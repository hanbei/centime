\section{Methoden der Evaluation}
\label{sec:centralityEvaluation}
Die Validierung der Themenverläufe stellt eine Schwierigkeit dieser Diplomarbeit dar. Bisher haben sich wenige Arbeiten mit der Evaluation von Themenverläufen beschäftigt. Es gibt dementsprechend wenige publizierte Ansätze zur Validation. In \citep{onlineLDA2} sollen Thementrends ähnlich zu dieser Diplomarbeit erkannt werden. Um den Algorithmus zu testen, werden Textsequenzen untersucht. Die Evaluation erfolgt nun durch zurückhalten von Dokumenten zu speziellen Themen, die ab einem vorher definierten Zeitpunkt in die Sequenz eingefügt werden. Entdeckt der Algorithmus diese Themen an dem definierten Zeitpunkt, wird dies als Erfolg gewertet. 

Diese Art der Evaluation wird in der Diplomarbeit auch verwendet. Es werden jedoch nicht reale Dokumente aus einem Testkorpus benutzt und Dokumente zurückgehalten, sondern die Dokumente werden künstlich erzeugt. Es wird der generative Prozess des LDA-Modells genutzt, um Dokumente zu erzeugen, die definierte Themen mit einer festen Wahrscheinlichkeit enthalten. Erzeugt man mehrere Dokumente auf diese Weise, können Testdaten erzeugt werden, die vorher definierte Themenverläufe aufweisen. Diese Testdaten werden dann dazu benutzt zu evaluieren, ob erstens die Verläufe tatsächlich entdeckt werden und wie gut sie durch den verwendeten Zentralitätsindex wiedergegeben werden. Dazu wird numerisch bestimmt, wie gut der Themenverlauf erfasst wird; einerseits von einer analytischen und andererseits von einer kognitiven Perspektive.

\subsection{Synthetische Verläufe}

Für jedes Themenmodell werden jeweils synthetische Textsequenzen erzeugt, anhand derer fest definierte Themenverläufe erzeugt werden. Es werden verschiedene Themenverläufe mit jeweils anderen Wahrscheinlichkeiten der Themen in den Dokumenten erzeugt. Insgesamt werden pro Themenmodell fünf Verläufe generiert, die sich in der Anzahl der Dokumente, der festgelegten Themen und deren Wahrscheinlichkeit unterscheiden. 

\begin{labeling}[:]{3TSw 0.2}
\item[3TSw 0.2] Eine Textsequenzen bestehend aus 120 Dokumenten. Jedes Dokument enthält drei Themen. Jeweils ein Thema und dessen Wahrscheinlichkeit ist vorher festgelegt. Die restlichen beiden Themen und deren Wahrscheinlichkeit werden zufällig ausgewählt. Es werden jeweils zehn Dokumente mit dem gleichen festgehaltenen Thema erzeugt. Die Wahrscheinlichkeit des Themas in den Dokumenten wird auf $0,2$ gesetzt. Nach 30 Dokumenten wird wieder das Thema der ersten zehn Dokumente gewählt. Es wird erwartet, dass bei einer Framegröße von zehn eine Sägezahnkurve auftritt, in der sich jeweils drei Themen abwechseln.   

\item[3TSw 0.8] Eine Textsequenzen wie in erstens, nur dass die Wahrscheinlichkeit des festgehaltenen Themas auf $0,8$ gesetzt wird. Auch hier wird wieder eine Säge"-zahnkurve erwartet jedoch mit anderen Werten der Zentralitätsindizes.
 
\item[CT 0.2] Eine Textsequenzen aus 100 Dokumenten die jeweils ein Thema festgelegt haben und zwei Themen zufällig gewählt. Die Wahrscheinlichkeit des festen Themas wurde auf $0,2$ gesetzt. Erwartet wird, dass das festgelegte Thema als prominentestes Thema auftritt und alle anderen Themen dominiert, da das Thema häufig zusammen mit anderen Themen auftritt.

\item[CT 0.8] Die Gleiche Textsequenzen wie in drittens nur das die Wahrscheinlichkeit auf $0,8$ gesetzt wurde.

\item[3TS] Eine Textsequenzen von 100 Dokumenten mit drei Themen die gleichzeitig prominent sind. Die Wahrscheinlichkeit wurde für alle Themen auf $0,2$ gesetzt. Zusätzlich wurden zufällig drei Themen ausgewählt, auf die   Restwahrscheinlichkeit von $0,4$ zufällig aufgeteilt wurde.
\end{labeling}

Da die wichtigen Themen in den Verläufen bekannt sind, kann numerisch ermittelt werden, wie gut diese vom System erkannt werden. Um dies zu evaluieren, wird ein dem Signal-Rausch-Verhältnis ($SRV$) verwandtes Maß \TODO{cite} benutzt, welches die Verläufe der relevanten Themen als Signal auffasst und die Zentralitätswerte als Signalstärke. Das Rauschen wird als der Mittelwert aller Themenverläufe aufgefasst. Betrachtet man nur die nicht relevanten Verläufe als Rauschen, unterscheiden sich diese oft nicht signifikant vom Mittelwert. Sie werden somit als relevant klassifiziert, obwohl sie im voraus nicht als solche definiert wurden. 

Ein Verlauf stellt für eine Thema die ermittelten Zentralitätswerte über die Zeit dar. Dementsprechend kann ein Verlauf eines Themas als Vektor $\vec{v}$ aufgefasst werden. Die Komponenten stellen den Zentralitätswert zu einem bestimmten Zeitpunkt dar. So ist $v_i$ der Zentralitätswert des Verlaufs zum Zeitpunkt $i$. Die Mittelwerte aller aller Verläufe werden mit $\vec{v_m}$ bezeichnet. Das Signal-Rausch-Verhältnis der einzelnen Werte ist definiert als
\[
SRV=10 \cdot \log_{10}\left({\frac{v_i}{v_{m_{i}}}}\right)
\]
und bewegt sich in diesem speziellen Anwendungsfall im Wertebereich $[-10,\ldots,10]$.

Wenn für einen Wert eines relevanten Verlaufs das $SRV$ größer als ein fester Wert $t$ ist, wird dieser Wert als richtig positiver Fall angenommen. Ist der Wert kleiner als $t$ wird er als falsch positiv angenommen. Für nicht relevante Verläufe wird auch das $SRV$ bestimmt. Ein $SRV$-Wert der größer als $t$ ist, wird als falsch positiv klassifiziert und ein Wert der kleiner als $t$ ist, als richtig negativ. Zählt man die einzelnen Auftreten von richtig positiv, falsch positiv usw. kann man die Trefferquote \[R = \frac{\text{richtig positiv}}{\text{richtig positiv} + \text{falsch negativ}}\] und die Genauigkeit \[P = \frac{\text{richtig positiv}}{\text{richtig positiv} + \text{falsch positiv}}\] bestimmen. Aus Trefferquote und Genauigkeit kann dann ein Wert \[F=\frac{2 \cdot P \cdot R}{P+R} \] berechnet werden, der angibt wie gut ein Verlauf erkannt wurde.

In den ersten Versuchen die Themenverläufe numerisch zu bewerten, wurde ein konstanter Schwellwert benutzt, um die richtig positiven und falsch positiven Fälle zu ermitteln. Wenn der Zentralitätswert eines relevanten Verlaufes über dem Schwellwert lag wurde er als richtig positiv gewertet und wenn der Zentralitätswert eines nicht relevanten Verlauf über dem Schwellwert lag, wurde er als falsch positiv klassifiziert. Es gab allerdings Konfigurationen der Themenverläufe, in denen die nicht relevanten Verläufe einen hohen Zentralitätswert aufwiesen, die relevanten Verläufe aber klar unterschieden werden konnten. Eine solche Konfiguration ist in Abbildung \ref{fig:allInOne} dargestellt. Hier ist im sechsten Frame das Thema \textit{kg co2} das relevante und die beiden anderen Themen irrelevant. Sie würden aber als falsch positiv bewertet, obwohl sich das Thema \textit{kg co2} klar von den beiden anderen Themen abhebt. Mit dem konstanten Schwellwert wurden somit die Bewertung schlechter, obwohl die die relevanten Verläufe klar als solche erkannt werden konnten. 

Es wurde deshalb das $SRV$ verwendet, um eine adaptive Methode zur Bewertung zu haben. Mit dem $SRV$ werden solche Konfigurationen der Verläufe richtig bewertet, da es hier auf das Verhältnis von relevantem zu nicht relevantem Verlauf ankommt. Trotz der hohen Zentralitätswerte der nicht relevanten Verläufe ist die Bewertung hoch, da das Verhältnis zwischen relevantem Themenverlauf und nicht relevantem Themenverlauf hoch genug ist, um diese voneinander zu unterscheiden.