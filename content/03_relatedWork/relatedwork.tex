\chapter{Verwandte Arbeiten}
\label{chap:relatedWork}

Viele andere Autoren haben schon den Versuch unternommen, aus Chatdaten Informationen zu extrahieren bzw. Themenmodelle um die Zeit zu erweitern. Einige dieser Arbeiten werden hier vorgestellt. Einerseits werden Arbeiten vorgestellt, die sich mit der Extraktion von Informationen aus Chattexten befassen. Diese Informationen sind nicht notwendigerweise automatisch ermittelte Themen und ein Teil der Arbeiten versucht auch nicht, die Zeit mit einzubeziehen. Diese Arbeiten wurden jedoch wegen der Analyse der Chattexte ausgewählt. Andererseits werden Arbeiten vorgestellt, die die Themenmodelle um die Zeit erweitern und dabei das Modell anpassen. 

\section{Analyse von Chattexten}

Eine Arbeit von Tuulos und Tirri versucht automatische Themen\-identifikation und soziale Netzwerke zu verbinden, um die Themen einer Diskussion stabiler zu identifizieren \citep{TMAndSocialNetworks}. Hier werden jedoch die Netzwerke anhand der Chatstruktur aufgebaut. Es wird betrachtet, welcher Sprecher einen anderen Sprecher adressiert. Anhand der so erstellten sozialen Netzwerke werden den Sprechern Gewichte zugeteilt. So können für komplette Chatkanäle die Themen bestimmt werden. Der Fokus dieser Arbeit liegt jedoch darauf, die Themen einer statischen Chatkollektion zu bestimmen und diese zur Indexierung der Chattexte zu nutzen. Die Chattexte werden hier nicht in zeitlichen Abschnitten betrachtet, sondern als Ganzes. Auch werden die Graphen anhand der sozialen Struktur der Sprecher bestimmt und nicht anhand der Kookkurrenz der Themen. 

Ein vergleichbares Retrieval System für Nachrichten in einem Internetforum auf der Basis von Themenmodellen wurde von Kim et. al entwickelt \citep{discussion_Kim2008Scaffolding}. Es werden für neue Nachrichten, die ein Student in das Forum postet, zusätzlich automatische Antworten aus dem Korpus alter Nachrichten herausgesucht. Dazu werden Nachrichten als Termvektoren von vorher definierten technischen und aufgabenspezifischen Termen modelliert. Ähnliche Nachrichten werden dann anhand des Kosinus-Maßes bestimmt, wobei die Nachrichten vorher nach Themen klassifiziert wurden und nur Nachrichten in die Ergebnismenge aufgenommen werden, die Übereinstimmungen in den Themen aufweisen \citep{discussion_Kim2006ontology}. Diese Arbeit zeigt, wie Themenmodelle und Forentexte dazu verwendet werden können, Schüler und Studenten in ihrem Lernen zu unterstützen.

Beide Arbeiten analysieren Chattexte nach vorkommenden Themen. Diese extrahierte Information wird aber nur zur Indizierung der Nachrichtenkanäle \citep{TMAndSocialNetworks} bzw. zum Auffinden automatischer Antworten genutzt \citep{discussion_Kim2008Scaffolding}. Es wird keine Information über die Zeit dargestellt, sondern die Chattexte werden als statische Sammlung von Texten betrachtet, die für spätere Suchen aufbereitet wurden.

Die folgenden Arbeiten sind näher mit dem Thema der Diplomarbeit verwandt. Hier werden die Veränderungen über die Zeit betrachtet. Es werden jedoch keine Themen identifiziert, sondern die Nachrichten in kommunikative Klassen eingeteilt. So werden in \citet{Anjewerden2007} die Chatnachrichten nach Funktionen klassifiziert. Dabei werden regulative, domänenspezifische, soziale und technische Funktionen unterschieden. Die Nachrichten werden dann in diese vier Klassen eingeteilt, indem erstens nur die vorkommenden Wörter betrachtet werden und in einem zweiten Schritt syntaktische Muster. Dazu werden die Nachrichten mit Part of Speech-Tags (POS-Tags) versehen und nach Mustern in den POS-Tagsequenzen klassifiziert. POS-Tags geben die syntaktische Funktion eines Wortes wieder. Es wird annotiert, ob ein Wort ein Verb oder ein Nomen ist oder eine andere Funktion besitzt. Wie in der Diplomarbeit werden zuerst die Klassen gelernt und dann neue Nachrichten online klassifiziert. Die Klassifikationsergebnisse bzw. das Verhältnis der klassifizierten Nachrichten zu Gesamtnachrichten werden dem Lernenden dann in aufbereiteter Form präsentiert. Dies soll den Lernenden auf etwaige Fokuswechsel hinweisen.

Einen ähnlichen Ansatz verfolgen McLaren et. al in \citep{Scheuer2008Helping,Miksatko2008Whats,Mclaren2007Using}. Sie versuchen durch Analyse des Chats dem Lehrer ein Instrument zur Steuerung der Diskussionen an die Hand zu geben. Dabei werden allerdings nicht die einfachen Chattexte betrachtet, sondern die Schüler nutzen ein graphisches Werkzeug um die Art ihrer Beiträge zu kennzeichnen und durch Verlinkung die Antwortstruktur darzustellen. So wird die Struktur der Diskussion als Graph dargestellt. Anhand dieser zusätzlichen Informationen werden Interaktionsmuster klassifiziert und diese dem Lehrer zugänglich gemacht. Die These ist, dass bestimmte Interaktionsmuster eine Intervention des Lehrers erforderlich machen, um die Diskussion zu steuern. Diese Arbeit hat einen ähnlichen Fokus wie die vorhergehende Arbeit \citep{discussion_Kim2008Scaffolding}. Es wird dem Lehrer ein Werkzeug an die Hand gegeben, um Diskussionen zu steuern und zu überwachen. 

Die Anwendung, die in dieser Diplomarbeit entwickelt wird, soll im SCY-Projekt ähnliche Hilfestellung geben, wie die beiden Anwendungen die in \citet{Anjewerden2007} und \citet{Miksatko2008Whats} entwickelt wurden. Einerseits soll dem Lehrer eine Möglichkeit gegeben werden Kommunikationsmuster zu erkennen und nötigenfalls in die Diskussion eingreifen, andererseits kann dem Lernenden direktes Feedback über die diskutierten Themen gegeben werden, um so eine eventuelle Selbstregulation zu bewirken.
 
In der Arbeit von Shaffer et. al. \citep{shafferEpistemicFrames} werden Schüler in die Rolle von Städteplanern versetzt und müssen eine Wohngegend umgestalten, bzw. deren weitere Nutzung planen. Dabei werden ihnen reale Daten und Szenarien präsentiert, auf deren Grundlage sie dann Entscheidungen treffen müssen. Da die Arbeitsumgebung als Webapplikation modelliert wird, können die Aktionen der Schüler aufgezeichnet werden. Die Idee dahinter ist, dass Schüler, die solch ein Szenario bearbeiten, in verschiedene Rollen, wie zum Beispiel Ingenieur, Architekt oder Stadtplaner schlüpfen.

Aus den anfallenden Daten soll dann die eingenommene Rolle ermittelt werden. Das wird anhand der transkribierten Unterhaltungen der Schüler analysiert. Insbesondere wird die Verände"-rung der Rollen über die Zeit betrachtet. Dazu werden, wie in der Diplomarbeit, mehrere Chatnachrichten in diskrete zeitliche Abschnitte zusammengefasst. Die einzelnen Nachrichten werden dann von Experten in die Rollenklassen eingeordnet. Diese Funktionsklassen werden dann als Knoten in einem Graphen dargestellt und je nach Auftreten in einem Zeitabschnitt durch Kanten verbunden. Je nach Anzahl der Auftreten der Rollenklassen, wird die Länge der Kanten zwischen den Knoten festgelegt. So werden Knoten, deren Rollen oft in einem Zeitabschnitt auftreten, näher beieinander liegen als solche die nicht oft zusammen auftreten. Die dabei entstehenden Graphen werden mit verschiedenen Metriken bewertet und die Werte über die Zeit aufgetragen. Insbesondere wird ein speziell entwickelter Zentralitätsindex (siehe Abschnitt \ref{subsec:degreecentrality}) dazu benutzt, die Knoten bzw. die repräsentierte Rolle zu bewerten. 

Meine Diplomarbeit baut direkt auf der Idee von Shaffer auf. Wie schon kurz beschrieben wurde, werden auch hier die Nachrichten in zeitliche Abschnitte aufgeteilt und quasi klassifiziert. Im Falle der Diplomarbeit werden, anstatt die Nachrichten manuell zu klassifizieren, die Themen automatisch ermittelt; die Themen ersetzen die Rollenklassen. Die ermittelten Themen werden ähnlich weiterverarbeitet wie in der Arbeit von Shaffer, es werden allerdings Erweiterungen im Aufbau des Graphen erprobt und unterschiedliche Zentralitätsindizes auf ihre Eignung für den speziellen Anwendungsfall der Diplomarbeit geprüft. 

\section{Erweiterungen von Themenmodellen auf Zeit}

Die in diesem Abschnitt vorgestellten Arbeiten beschäftigen sich nicht mehr mit Chattexten, sondern versuchen - wie auch in der Diplomarbeit verwendete - LDA-Modell mit einer zeitlichen Komponente zu erweitern. Linstead et. .al \citep{ldaSourceCode} verfolgt dabei den einfachsten Ansatz, in welchem für aufeinander folgende Versionen eines Softwaresystems die Themen gelernt werden und gezählt wird, wie oft die Themen in einer Version auftreten. Für die einzelnen Themen wird dann aufgetragen, wie oft sie in den einzelnen Versionen vorkommen. Dabei wird aber nur die absolute Anzahl der auftretenden Themen betrachtet und die Wahrscheinlichkeit eines Themas unberücksichtigt gelassen. Außerdem eignet sich dieser Ansatz nicht für die Diplomarbeit, da jedes mal ein neues Modell gelernt wird und dies erstens einen erheblichen Rechenaufwand darstellt und zweitens die Themen verschiedener gelernter Modelle einander wieder zugeordnet werden müssen.

Eine weitere Anwendung, die ohne aufwändige Anpassung des LDA-Modell auskommt, wird in \citep{onlineLDA2} beschrieben. In dieser Arbeit wird das Modell kontinuierlich erweitert. Die Themen werden durch unbekannte Dokumente verändert. Dies wird erreicht, indem für neue Dokumente während der Inferenz der Themen die Themen- und Termverteilungen des Modells angepasst werden. So wird erreicht, dass die Themen sich über die Zeit verändern. Als Folge, verschieben die Themen möglicherweise ihren Fokus. Dies ist für diese Diplomarbeit ein nicht gewünschter Effekt, da durch die SCY-Missionen die Themen vorgegeben sind und sich diese durch neue Dokumente nicht ändern sollen. Es wird deshalb die in den Grundlagen dargestellte Methode zur Inferenz der Themen neuer Dokumente genutzt, die ohne Veränderung der Themen- und Termverteilungen auskommt. 

McCallum et. al. \citep{topicsOverTime} ist eine Arbeit, in der das LDA-Modell zum Topics Over Time (TOT) Modell erweitert wird. Zusätzlich zu den Wörtern wird für jedes Dokument ein Zeitpunkt beobachtet und die Themen werden ferner anhand dieser Zeitpunkte konditioniert. Es werden also Themenverteilungen für Zeitpunkte gelernt. Dies erlaubt es, die Verteilung der Themen über die Zeit zu betrachten. Allerdings muss das TOT-Modell jedes mal aufwändig gelernt werden, wenn neue Dokumente bzw. die Verteilung der Themen über die Zeit für diese neuen Dokumente ermittelt werden soll. Es gibt einen Ansatz, der es erlaubt, ein Themenmodell kontinuierlich weiter zu trainieren \citep{onlineLDA}. Würde man diesen Ansatz auf das TOT-Modell erweitern, könnte man die neuen Variablen online lernen. Dies könnte man als Erweiterung der Diplomarbeit in Erwägung ziehen. Der Fokus liegt jedoch darauf, aus vorher gelernten Themen, insbesondere im SCY-Kontext, die Verläufe zu bestimmen.

Eine andere Technik, die von Blei und Lafferty entwickelt wurde \citep{dynamicTopicModels}, versucht die Zeit in das LDA-Modell zu integrieren, indem für diskrete Zeitabschnitte jeweils ein Modell trainiert wird, das auf dem vorhergehenden Modell basiert. Dabei werden die Themenverteilungen für Dokumente und die Wortverteilungen für Themen eines Zeitabschnittes $t$ aufgrund der Hyperparameter $\alpha$ und $\beta$ der vorhergehenden Zeitabschnitte $(1,\ldots,t-1)$ ermittelt (siehe Abschnitt \ref{sec:topicModels}). Hierbei verändern sich die Wörter, aus denen ein Thema aufgebaut ist. Dies ist im Kontext einer Analyse von Texten, in der sich die Terminologie ändert, das gewünschte Verhalten. In der Diplomarbeit wird jedoch von einem auf Hintergrundwissen trainierten Modell ausgegangen, anhand dessen die im Chat behandelten Themen erkannt werden können. 

\section{Zusammenfassung}
Die vorgestellten Arbeiten in diesem Kapitel zeigen Ansätze auf, um aus Chattexten Informationen zu extrahieren und wie das Modell der LDA um die Zeit erweitert werden kann. Die Arbeiten, die sich mit der Extraktion von Informationen aus Chattexten beschäftigen, verwenden jedoch entweder keine Themenmodelle, sondern ordnen die Nachrichten in bestimmte vordefinierte Klassen ein oder betrachten nicht die zeitliche Veränderung. 

Die Arbeiten, die das LDA-Modell erweitern, weisen eine komplizierte Implementierung oder eine hohe Laufzeit auf. Die in der Diplomarbeit entwickelte Methode benötigt im Gegensatz zu vorgestellten Arbeiten keine schwierige Anpassung des LDA-Modells. Auch wird in diesen Arbeit oftmals die Zeit mit gelernt, während die Diplomarbeit versucht, die Veränderung der Themen online zu erfassen, ohne die Themenmodelle zu erweitern.   


