\chapter{Diskussion}

In dieser Diplomarbeit wurde eine Methode entwickelt, um zeitliche Veränderungen in der Thematik von Texten zu erfassen. Dazu wurden Themenmodelle aus Hintergrundtexten trainiert, um die Themen der Texte erfassen zu können. Ausgehend von diesen Themenmodellen wurde die zeitliche Veränderung der Themen in Textsequenzen erfasst, indem diese zuerst in Zeitabschnitt aufgeteilt wurden. Anschließend wurde dann die Kookkurrenz der Themen der Dokumente, die in einem Zeitabschnitt enthalten sind, in einem Graphen kodiert. Auf jeden Graphen eines Zeitabschnittes wurde dann ein Zentralitätsmaß angewendet, um die Prominenz der Themen über die Zeit zu verfolgen. 

Dazu mussten verschiedene Aufgaben gelöst und Algorithmen entwickelt werden. So musste eine Methode entwickelt werden, wie die Textsequenzen in Zeitabschnitte unterteilt werden können. Die Themenkookkurrenz der in diesen Zeitabschnitten vorkommenden Dokumente mussten als Graphen kodieren werden. Zu diesem Zweck wurden die drei Algorithmen aus Abschnitt \ref{sec:topic2graph} entwickelt. Für die Graphen mussten die verschiedenen Zentralitätsmaße implementiert werden. Schlussendlich musste eine geeignete Visualisierung der Themenverläufe gefunden und implementiert werden. 
Zusätzlich wurden die Verfahren zur Bestimmung der optimalen Themenanzahl und der Evaluation der Themenverläufe entwickelt, da es bisher keine geeigneten Verfahren gab, um die optimale Themenanzahl von Themenmodellen nur anhand der gelernten Modelle ohne Zurückhalten von Dokumenten zu bestimmen. Eine numerische Evaluation von Themenverläufen wurde bisher auch noch nicht durchgeführt, deshalb wurde das hier dargestellte Evaluationsverfahren entwickelt.

Mit der Entwicklung und Implementierung der Methoden und Algorithmen konnten verschieden Fragestellungen untersucht werden. Die zentrale zu lösende Fragestellung der Diplomarbeit war es, zu untersuchen, welche Zentralitätsmaße, auf die verschiedenen erstellten Graphen angewandt, die Themenveränderung am besten erfassen. Zusätzlich wurde der Einfluss verschiedener Parameter auf die Erfassung der Themenänderungen untersucht. Zum einen mussten in der Lernphase die Themenmodelle bestimmt werden, die das zugrundeliegende Korpus am besten repräsentieren, bzw. die optimale Anzahl von Themen musste bestimmt werden. Zum anderen wurden Themenmodelle mit unterschiedlichen Parametern trainiert und der Effekt dieser Parametervariation auf die Erfassung der Themenverläufe wurde untersucht. So wurden Modelle mit Stopwortentfernung und Stammformreduktion trainiert, Modelle, für die nur eine Stopwortentfernung oder Stammformreduktion durchgeführt wurde und ein Modell, welches weder Stopwortentfernung noch Stammformreduktion im Vorverarbeitungsschritt enthält. Die Größe der Frames und die Größe der Überlappung spielt auch eine wesentliche Rolle bei der Erfassung der Themenverläufe. Diese wurden jedoch nur empirisch für die realen Textsequenzen ermittelt. Eine genauere Untersuchung zum Einfluss der Framegröße auf die Erfassung der Themenveränderung wurde aus Zeitgründen nicht mehr durchgeführt.

Die so entwickelte Methode, um die Veränderung in der Prominenz von Themen über die Zeit zu erfassen, zeigte gute Ergebnisse   
für die Betweenness-Zentralität auf Graphen die mit den Algorithmen \CDC$\:$und \TPR$\:$erstellt wurden. Die synthetisch erzeugten Verläufe und die realen Verläufe wurden korrekt erfasst und wiedergegeben. Die Variation der Parameter zum Training der Themenmodelle zeigte keinen signifikanten Einfluss auf die Qualität der Themenerfassung. Es hat sich jedoch gezeigt, dass die numerische Bewertung teilweise nicht mit der manuell visuellen Bewertung übereinstimmt. So wurden Verläufe schlecht bewertet, obwohl sie visuell klar erkennbar und gut zu unterscheiden waren. Ein weiterer Nachteil der hier entwickelten Methoden stellt die Wahl der Framegröße dar. Die Framegröße und die Überlappung werden fest gewählt und müssen je nach betrachteter Textsequenz manuell ermittelt werden, um Zeitabschnitte zu repräsentieren. Es wäre denkbar die Framegröße und Überlappung automatisch bestimmen zu lassen und die Framegröße variieren zu lassen. 

Auch ist es nötig für die Bestimmung der optimalen Themenanzahl für die Themenmodelle viele Themenmodelle zu trainieren um die Bewertung zu vergleichen. Es kann kein absoluter Wert angegeben werden, ab dem ein Themenmodelle als geeignet betrachtet werden kann. Die optimale Anzahl von Themen ist immer nur im direkten Vergleich verschieden parametrisierter Modelle zu ermitteln. Es wäre zu untersuchen, ob die Anzahl der zu trainierenden Modelle durch Ziehen von Stichproben gesenkt werden kann. 

Dies beschränkt sich jedoch auf die Lernphase, die offline durchgeführt werden kann. In der Anwendungsphase müssen die Modelle nicht aufwändig angepasst oder neu trainiert werden. Die entwickelte Methode kann somit als Online-Algorithmus verwendet werden, um kontinuierliche Textströme zu untersuchen. Weiterhin berücksichtigt die hier entwickelte Methode, im Gegensatz zu anderen Ansätzen wie zum Beispiel \citep{ldaSourceCode}, die Wahrscheinlichkeit der Themen; einerseits implizit, wie im Algorithmus \CDC$\;$beschrieben und andererseits explizit, wie im Algorithmus \TPR. 

\section{Ausblick}

Die hier entwickelte Methode lässt sich nicht nur dazu einsetzen, Themenverläufe in Nachrichtenmeldungen oder Chats von Schülern zu überwachen. Es wäre zusätzlich denkbar, die Überwachung auf bestimmte Themen einzuschränken, um das Aufkommen bestimmter Themen zu entdecken. Im Kontext des SCY-Projektes könnte der Fokus von Diskussionen von einem Lehrer gesteuert werden oder es wäre denkbar anhand der behandelten Themen einer Diskussion Rückschlüsse auf den Lernfortschritt der Schüler zu ziehen. Hält sich die Diskussion sehr lange mit einem Thema auf, könnte dies darauf hinweisen, dass das Thema nicht richtig verstanden wurde und zusätzlicher Lernbedarf besteht. Andererseits kann über die Prominenz der Themen festgestellt werden, dass die Schüler ein Thema verstanden haben. Erscheint ein Thema am Anfang einer Diskussion sehr wenig und wird über die Zeit prominenter könnte man daraus schließen, dass die Schüler das Thema besser verstehen als am Anfang, da mehr Fachvokabular benutzt wird, so dass das Thema öfter als prominent gewertet wird. Ob sich die hier entwickelte Methode dazu eignet, solche Lernmuster zu entdecken muss jedoch noch untersucht werden. 

Werden zusätzlich zu den Termen der Dokumente andere Merkmale der untersuchten Dokumente hinzugezogen, können auch andere Verläufe untersucht werden. So ist es möglich die syntaktische Struktur der untersuchten Dokumente als Merkmal mit einzubeziehen. Trainiert man ein Themenmodell mit der Syntax der Dokumente als Merkmal, könnten Themen entstehen, die bestimmte rhetorische Muster gruppieren. Anhand dieser rhetorischen Themen kann dann unter Umständen die Argumentationsstruktur einer Diskussion verfolgt werden. Dies gilt es aber noch zu untersuchen.

Zusätzlich wäre es interessant zu untersuchen, inwieweit die Nutzung von adaptiven Themenmodellen, wie sie in \citep{topicsOverTime} oder \citep{onlineLDA} dargestellt wurden, die Erfassung von Themen in Nachrichtentexten verändert. Für die Anwendung im SCY-Projekt ist das statische Themenmodell ausreichend, da sich die Hintergrundtexte nicht verändern und die Schüler kein neues fachliches Vokabular entwickeln. Für die Anwendung in realen Szenarien wäre es zusätzlich denkbar, die Themen, die nur Funktionswörter gruppieren und keinen semantische Inhalt automatisch aufweisen, speziell zu kennzeichnen. So könnte man diese, wenn sie, wie im Falle der dpa-Nachrichtenmeldungen unerwünscht sind, ausblenden. Im Falle der SCY-Chattexte könnten die Funktionswortthemen speziell überwacht werden und festgestellt werden, wann die Schüler von der zu bearbeitenden Aufgabe abweichen und etwas anderes tun. 


